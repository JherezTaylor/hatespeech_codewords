{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Retrieve parsed collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from modules.db import mongo_base\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# connection_params = [\"twitter\", \"crowdflower_features\"]\n",
    "# client = mongo_base.connect()\n",
    "# db_name = connection_params[0]\n",
    "# connection_params.insert(0, client)\n",
    "\n",
    "# query = {}\n",
    "# query[\"filter\"] = {}\n",
    "# query[\"projection\"] = {}\n",
    "# query[\"limit\"] = 0\n",
    "# query[\"skip\"] = 0\n",
    "# query[\"no_cursor_timeout\"] = True\n",
    "# cursor = mongo_base.finder(connection_params, query, False)\n",
    "# df = pd.DataFrame(list(cursor))\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "crowdflower_persistence = 'data/persistence/crowdflower_features.pkl.compressed'\n",
    "# joblib.dump(df, crowdflower_persistence, compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df = joblib.load(crowdflower_persistence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>brown_cluster_ids</th>\n",
       "      <th>char_pentagrams</th>\n",
       "      <th>char_quadgrams</th>\n",
       "      <th>char_trigrams</th>\n",
       "      <th>comment_length</th>\n",
       "      <th>dep_bigrams</th>\n",
       "      <th>...</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>hs_keyword_count</th>\n",
       "      <th>hs_keyword_matches</th>\n",
       "      <th>noun_chunks</th>\n",
       "      <th>text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>trigrams</th>\n",
       "      <th>unknown_words</th>\n",
       "      <th>unknown_words_count</th>\n",
       "      <th>uppercase_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58c659be6541913eb7f119dd</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[Warning penny, penny boards, boards will, wil...</td>\n",
       "      <td>[966, 228, 989, 333, 442, 4618, 602, 19]</td>\n",
       "      <td>[penny, warni, arnin, aggot, board, rning, fag...</td>\n",
       "      <td>[aggo, warn, arni, penn, oard, ards, enny, nin...</td>\n",
       "      <td>[pen, war, nin, mak, enn, you, agg, ggo, fag, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>[warning ROOT NN warning | boards compound NN ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>[faggot]</td>\n",
       "      <td>[{'root': 'warning', 'text': 'warning'}, {'roo...</td>\n",
       "      <td>Warning : penny boards will make you a faggot</td>\n",
       "      <td>[penny, faggot, warning, boards]</td>\n",
       "      <td>[Warning penny boards, penny boards will, boar...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id annotation_label  avg_token_length  \\\n",
       "0  58c659be6541913eb7f119dd    not_offensive               4.0   \n",
       "\n",
       "                                             bigrams  \\\n",
       "0  [Warning penny, penny boards, boards will, wil...   \n",
       "\n",
       "                          brown_cluster_ids  \\\n",
       "0  [966, 228, 989, 333, 442, 4618, 602, 19]   \n",
       "\n",
       "                                     char_pentagrams  \\\n",
       "0  [penny, warni, arnin, aggot, board, rning, fag...   \n",
       "\n",
       "                                      char_quadgrams  \\\n",
       "0  [aggo, warn, arni, penn, oard, ards, enny, nin...   \n",
       "\n",
       "                                       char_trigrams  comment_length  \\\n",
       "0  [pen, war, nin, mak, enn, you, agg, ggo, fag, ...               9   \n",
       "\n",
       "                                         dep_bigrams          ...           \\\n",
       "0  [warning ROOT NN warning | boards compound NN ...          ...            \n",
       "\n",
       "  hashtags hs_keyword_count hs_keyword_matches  \\\n",
       "0       []                1           [faggot]   \n",
       "\n",
       "                                         noun_chunks  \\\n",
       "0  [{'root': 'warning', 'text': 'warning'}, {'roo...   \n",
       "\n",
       "                                             text  \\\n",
       "0  Warning : penny boards will make you a faggot    \n",
       "\n",
       "                             tokens  \\\n",
       "0  [penny, faggot, warning, boards]   \n",
       "\n",
       "                                            trigrams unknown_words  \\\n",
       "0  [Warning penny boards, penny boards will, boar...            []   \n",
       "\n",
       "  unknown_words_count uppercase_token_count  \n",
       "0                   0                     0  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's pick the same random 10% of the data to train with\n",
    "train_test_set = df.sample(n=int(len(df) / 2), random_state=1965)\n",
    "\n",
    "X = train_test_set['text']\n",
    "y = train_test_set['annotation_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the labels of the test set...\n",
      "1450 documents\n",
      "2 categories\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicting the labels of the test set...\")\n",
    "print(\"%d documents\" % len(X))\n",
    "print(\"%d categories\" % len(y.value_counts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup naive baseline classification (countVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: CountVectorizer\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   hatespeech       0.42      0.41      0.42       304\n",
      "not_offensive       0.88      0.89      0.88      1510\n",
      "\n",
      "  avg / total       0.81      0.81      0.81      1814\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 126  178]\n",
      " [ 173 1337]]\n",
      "0.806504961411\n"
     ]
    }
   ],
   "source": [
    "# our two ingredients: the ngram counter and the classifier\n",
    "vect = CountVectorizer(ngram_range=(3,5), analyzer='char')\n",
    "clf = LinearSVC()\n",
    "\n",
    "# There are just two steps to our process: extracting the ngrams and\n",
    "# putting them through the classifier. So our Pipeline looks like this:\n",
    "\n",
    "count_pipeline = Pipeline([\n",
    "    ('vect', vect),  # extract ngrams from tweet text\n",
    "    ('clf' , clf),   # feed the output through a classifier\n",
    "])\n",
    "\n",
    "def naive_experiment(X, y, pipeline, num_expts=1):\n",
    "    scores = list()\n",
    "    for i in range(num_expts):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        model = count_pipeline.fit(X_train, y_train)  # train the classifier\n",
    "        y_prediction = model.predict(X_test)          # apply the model to the test data\n",
    "        report = classification_report(y_test, y_prediction)\n",
    "        score = accuracy_score(y_prediction, y_test)  # compare the results to the gold standard\n",
    "        scores.append(score)\n",
    "        print(\"Classification Report: CountVectorizer\")\n",
    "        print(report)\n",
    "        cm = confusion_matrix(y_test, y_prediction)\n",
    "        print(\"Confusion matrix:\")\n",
    "        print(cm)\n",
    "    print(sum(scores) / num_expts)\n",
    "\n",
    "# Run the classifcation\n",
    "naive_experiment(X, y, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup naive baseline classification (hashingVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report : HashingVectorizer\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   hatespeech       0.55      0.39      0.46       282\n",
      "not_offensive       0.89      0.94      0.92      1532\n",
      "\n",
      "  avg / total       0.84      0.86      0.85      1814\n",
      "\n",
      "Confusion matrix:\n",
      "[[ 111  171]\n",
      " [  90 1442]]\n",
      "0.85611907387\n"
     ]
    }
   ],
   "source": [
    "# our two ingredients: the ngram counter and the classifier\n",
    "vect = HashingVectorizer(ngram_range=(3,5), analyzer='char')\n",
    "clf = LinearSVC()\n",
    "\n",
    "# There are just two steps to our process: extracting the ngrams and\n",
    "# putting them through the classifier. So our Pipeline looks like this:\n",
    "\n",
    "hashing_pipeline = Pipeline([\n",
    "    ('vect', vect),  # extract ngrams from tweet text\n",
    "    ('clf' , clf),   # feed the output through a classifier\n",
    "])\n",
    "\n",
    "def hashing_experiment(X, y, pipeline, num_expts=1):\n",
    "    scores = list()\n",
    "    for i in range(num_expts):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        model = hashing_pipeline.fit(X_train, y_train)  # train the classifier\n",
    "        y_prediction = model.predict(X_test)          # apply the model to the test data\n",
    "        report = classification_report(y_test, y_prediction)\n",
    "        score = accuracy_score(y_prediction, y_test)  # compare the results to the gold standard\n",
    "        scores.append(score)\n",
    "        print(\"Classification Report : HashingVectorizer\")\n",
    "        print(report)\n",
    "        cm = confusion_matrix(y_test, y_prediction)\n",
    "        print(\"Confusion matrix:\")\n",
    "        print(cm)\n",
    "    print(sum(scores) / num_expts)\n",
    "\n",
    "# Run the classifcation\n",
    "hashing_experiment(X, y, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup tf-idf baseline classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report : TfidfVectorizer\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   hatespeech       0.54      0.31      0.39       308\n",
      "not_offensive       0.87      0.94      0.91      1506\n",
      "\n",
      "  avg / total       0.81      0.84      0.82      1814\n",
      "\n",
      "Confusion matrix:\n",
      "[[  96  212]\n",
      " [  83 1423]]\n",
      "0.837375964719\n"
     ]
    }
   ],
   "source": [
    "# our two ingredients: the ngram counter and the classifier\n",
    "vect = TfidfVectorizer(ngram_range=(3,5), analyzer='char')\n",
    "clf = LinearSVC()\n",
    "\n",
    "# There are just two steps to our process: extracting the ngrams and\n",
    "# putting them through the classifier. So our Pipeline looks like this:\n",
    "\n",
    "hashing_pipeline = Pipeline([\n",
    "    ('vect', vect),  # extract ngrams from tweet text\n",
    "    ('clf' , clf),   # feed the output through a classifier\n",
    "])\n",
    "\n",
    "def tfidf_experiment(X, y, pipeline, num_expts=1):\n",
    "    scores = list()\n",
    "    for i in range(num_expts):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        model = hashing_pipeline.fit(X_train, y_train)  # train the classifier\n",
    "        y_prediction = model.predict(X_test)          # apply the model to the test data\n",
    "        report = classification_report(y_test, y_prediction)\n",
    "        score = accuracy_score(y_prediction, y_test)  # compare the results to the gold standard\n",
    "        scores.append(score)\n",
    "        print(\"Classification Report : TfidfVectorizer\")\n",
    "        print(report)\n",
    "        cm = confusion_matrix(y_test, y_prediction)\n",
    "        print(\"Confusion matrix:\")\n",
    "        print(cm)\n",
    "    print(sum(scores) / num_expts)\n",
    "\n",
    "# Run the classifcation\n",
    "tfidf_experiment(X, y, pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
