{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building\n",
    "\n",
    "This is a staging notebook for experiments related to the classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim import models, similarities\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "import joblib\n",
    "from modules.db import mongo_base\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.feature_extraction import FeatureHasher, DictVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from modules.utils.CustomTwokenizer import CustomTwokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store collection as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_as_df(connection_params, projection):\n",
    "    client = mongo_base.connect()\n",
    "    db_name = connection_params[0]\n",
    "    connection_params.insert(0, client)\n",
    "    query = {}\n",
    "    query[\"filter\"] = {}\n",
    "    query[\"projection\"] = projection\n",
    "    query[\"limit\"] = 0\n",
    "    query[\"skip\"] = 0\n",
    "    query[\"no_cursor_timeout\"] = True\n",
    "    cursor = mongo_base.finder(connection_params, query, False)\n",
    "    df = pd.DataFrame(list(cursor))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge dataframes [CrowdFlower Dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "connection_params_1 = [\"twitter\", \"crowdflower_features\"]\n",
    "connection_params_2 = [\"twitter\", \"crowdflower_features_emo\"]\n",
    "# df = fetch_as_df(connection_params_1, {})\n",
    "# df_emo = fetch_as_df(connection_params_2, {\"emotions\":1})\n",
    "# df = pd.DataFrame.merge(df, df_emo, on=\"_id\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle the raw feature collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spacy_en_model = \"en_core_web_md\"\n",
    "spacy_glove_model = \"en_vectors_glove_md\"\n",
    "crowdflower_persistence_raw = 'data/persistence/df/crowdflower_features_raw.pkl.compressed'\n",
    "crowdflower_persistence = 'data/persistence/df/crowdflower_features.pkl.compressed'\n",
    "naacl_2016_persistence = 'data/persistence/df/naacl_2016.pkl.compressed'\n",
    "nlp_2016_persistence = 'data/persistence/df/nlp_2016.pkl.compressed'\n",
    "# nlp = spacy.load(spacy_en_model, create_make_doc=CustomTwokenizer)\n",
    "# joblib.dump(df, crowdflower_persistence_raw, compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = joblib.load(crowdflower_persistence_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe with classifier features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# feat_df = df[['_id', 'text', 'annotation_label', 'hs_keyword_matches', 'hs_keyword_count', 'unknown_words', 'unknown_words_count', 'comment_length', 'brown_cluster_ids', 'feat_dependency_contexts', 'feat_word_dep_root', 'feat_pos_dep_rootPos', 'feat_word_root_rootparent', 'feat_dep_unigrams', 'feat_dep_bigrams', 'feat_dep_trigrams']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>hs_keyword_matches</th>\n",
       "      <th>hs_keyword_count</th>\n",
       "      <th>unknown_words</th>\n",
       "      <th>unknown_words_count</th>\n",
       "      <th>comment_length</th>\n",
       "      <th>brown_cluster_ids</th>\n",
       "      <th>feat_dependency_contexts</th>\n",
       "      <th>feat_word_dep_root</th>\n",
       "      <th>feat_pos_dep_rootPos</th>\n",
       "      <th>feat_word_root_rootparent</th>\n",
       "      <th>feat_dep_unigrams</th>\n",
       "      <th>feat_dep_bigrams</th>\n",
       "      <th>feat_dep_trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58c659be6541913eb7f119dd</td>\n",
       "      <td>Warning : penny boards will make you a faggot</td>\n",
       "      <td>not_offensive</td>\n",
       "      <td>[faggot]</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>[966, 228, 442, 4618, 602, 19]</td>\n",
       "      <td>[warning_:_punct, warning_make_acl, penny boar...</td>\n",
       "      <td>[warning_ROOT_warning, penny boards_nsubj_make...</td>\n",
       "      <td>[NN_ROOT_NN, NNS_nsubj_VB, MD_aux_VB, VB_acl_N...</td>\n",
       "      <td>[warning_warning_warning, penny boards_make_wa...</td>\n",
       "      <td>[warning_warning_ROOT_NN, penny boards_make_ns...</td>\n",
       "      <td>[warning_warning_ROOT_NN|penny boards_make_nsu...</td>\n",
       "      <td>[warning_warning_ROOT_NN|penny boards_make_nsu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58c659be6541913eb7f119de</td>\n",
       "      <td>Fuck dykes</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>[fuck_dykes_compoundINV, dykes_fuck_compound]</td>\n",
       "      <td>[fuck_compound_dykes, dykes_ROOT_dykes]</td>\n",
       "      <td>[NNP_compound_VBZ, VBZ_ROOT_VBZ]</td>\n",
       "      <td>[fuck_dykes_dykes, dykes_dykes_dykes]</td>\n",
       "      <td>[fuck_dykes_compound_NNP, dykes_dykes_ROOT_VBZ]</td>\n",
       "      <td>[fuck_dykes_compound_NNP|dykes_dykes_ROOT_VBZ]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58c659be6541913eb7f119df</td>\n",
       "      <td>user_mention user_mention user_mention user_me...</td>\n",
       "      <td>hatespeech</td>\n",
       "      <td>[faggot]</td>\n",
       "      <td>1</td>\n",
       "      <td>[jefree]</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>[124, 3690, 966, 2442, 1684]</td>\n",
       "      <td>[user_mention user_mention user_mention user_m...</td>\n",
       "      <td>[user_mention user_mention user_mention user_m...</td>\n",
       "      <td>[NN_ROOT_NN, IN_advmod_JJS, JJS_advmod_VBP, PR...</td>\n",
       "      <td>[user_mention user_mention user_mention user_m...</td>\n",
       "      <td>[user_mention user_mention user_mention user_m...</td>\n",
       "      <td>[user_mention user_mention user_mention user_m...</td>\n",
       "      <td>[user_mention user_mention user_mention user_m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  58c659be6541913eb7f119dd   \n",
       "1  58c659be6541913eb7f119de   \n",
       "2  58c659be6541913eb7f119df   \n",
       "\n",
       "                                                text annotation_label  \\\n",
       "0     Warning : penny boards will make you a faggot     not_offensive   \n",
       "1                                        Fuck dykes        hatespeech   \n",
       "2  user_mention user_mention user_mention user_me...       hatespeech   \n",
       "\n",
       "  hs_keyword_matches  hs_keyword_count unknown_words  unknown_words_count  \\\n",
       "0           [faggot]                 1            []                    0   \n",
       "1                 []                 0            []                    0   \n",
       "2           [faggot]                 1      [jefree]                    1   \n",
       "\n",
       "   comment_length               brown_cluster_ids  \\\n",
       "0               9  [966, 228, 442, 4618, 602, 19]   \n",
       "1               2                              []   \n",
       "2              14    [124, 3690, 966, 2442, 1684]   \n",
       "\n",
       "                            feat_dependency_contexts  \\\n",
       "0  [warning_:_punct, warning_make_acl, penny boar...   \n",
       "1      [fuck_dykes_compoundINV, dykes_fuck_compound]   \n",
       "2  [user_mention user_mention user_mention user_m...   \n",
       "\n",
       "                                  feat_word_dep_root  \\\n",
       "0  [warning_ROOT_warning, penny boards_nsubj_make...   \n",
       "1            [fuck_compound_dykes, dykes_ROOT_dykes]   \n",
       "2  [user_mention user_mention user_mention user_m...   \n",
       "\n",
       "                                feat_pos_dep_rootPos  \\\n",
       "0  [NN_ROOT_NN, NNS_nsubj_VB, MD_aux_VB, VB_acl_N...   \n",
       "1                   [NNP_compound_VBZ, VBZ_ROOT_VBZ]   \n",
       "2  [NN_ROOT_NN, IN_advmod_JJS, JJS_advmod_VBP, PR...   \n",
       "\n",
       "                           feat_word_root_rootparent  \\\n",
       "0  [warning_warning_warning, penny boards_make_wa...   \n",
       "1              [fuck_dykes_dykes, dykes_dykes_dykes]   \n",
       "2  [user_mention user_mention user_mention user_m...   \n",
       "\n",
       "                                   feat_dep_unigrams  \\\n",
       "0  [warning_warning_ROOT_NN, penny boards_make_ns...   \n",
       "1    [fuck_dykes_compound_NNP, dykes_dykes_ROOT_VBZ]   \n",
       "2  [user_mention user_mention user_mention user_m...   \n",
       "\n",
       "                                    feat_dep_bigrams  \\\n",
       "0  [warning_warning_ROOT_NN|penny boards_make_nsu...   \n",
       "1     [fuck_dykes_compound_NNP|dykes_dykes_ROOT_VBZ]   \n",
       "2  [user_mention user_mention user_mention user_m...   \n",
       "\n",
       "                                   feat_dep_trigrams  \n",
       "0  [warning_warning_ROOT_NN|penny boards_make_nsu...  \n",
       "1                                                 []  \n",
       "2  [user_mention user_mention user_mention user_m...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joblib.dump(feat_df, crowdflower_persistence, compress=True)\n",
    "feat_df = joblib.load(crowdflower_persistence)\n",
    "feat_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch NAACL_SRW_2016 and NLP+CSS_2016 datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connection_params_3 = [\"twitter\", \"NAACL_SRW_2016_features\"]\n",
    "# connection_params_4 = [\"twitter\", \"NLP_CSS_2016_expert_features\"]\n",
    "# df_naacl = fetch_as_df(connection_params_3, {})\n",
    "# df_nlp = fetch_as_df(connection_params_4, {})\n",
    "# joblib.dump(df_naacl, naacl_2016_persistence, compress=True)\n",
    "# joblib.dump(df_nlp, nlp_2016_persistence, compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>annotation</th>\n",
       "      <th>avg_token_length</th>\n",
       "      <th>brown_cluster_ids</th>\n",
       "      <th>comment_length</th>\n",
       "      <th>feat_dep_bigrams</th>\n",
       "      <th>feat_dep_trigrams</th>\n",
       "      <th>feat_dep_unigrams</th>\n",
       "      <th>feat_dependency_contexts</th>\n",
       "      <th>feat_pos_dep_rootPos</th>\n",
       "      <th>feat_word_dep_root</th>\n",
       "      <th>feat_word_root_rootparent</th>\n",
       "      <th>has_hs_keywords</th>\n",
       "      <th>hs_keyword_count</th>\n",
       "      <th>hs_keyword_matches</th>\n",
       "      <th>text</th>\n",
       "      <th>unknown_words</th>\n",
       "      <th>unknown_words_count</th>\n",
       "      <th>uppercase_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>591c29f465419158a43b735d</td>\n",
       "      <td>neither</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[166, 1914, 12, 5829, 1020, 12, 5098, 20, 5098...</td>\n",
       "      <td>29</td>\n",
       "      <td>[cisco_had_nsubj_NNP|had_allow_aux_VBD, had_al...</td>\n",
       "      <td>[cisco_had_nsubj_NNP|had_allow_aux_VBD|to_deal...</td>\n",
       "      <td>[cisco_had_nsubj_NNP, had_allow_aux_VBD, to_de...</td>\n",
       "      <td>[cisco_had_nsubjINV, had_cisco_nsubj, had_deal...</td>\n",
       "      <td>[NNP_nsubj_VBD, VBD_aux_VB, TO_aux_VB, VB_xcom...</td>\n",
       "      <td>[cisco_nsubj_had, had_aux_allow, to_aux_deal, ...</td>\n",
       "      <td>[cisco_had_allow, had_allow_allow, to_deal_had...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Cisco had to deal with a fat cash payout to th...</td>\n",
       "      <td>[fsf, compliancy]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>591c29f465419158a43b735e</td>\n",
       "      <td>neither</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[551, 124, 3050, 4]</td>\n",
       "      <td>9</td>\n",
       "      <td>[user_mention_i'm_nsubj_NN|i'm_i'm_ROOT_VBZ, i...</td>\n",
       "      <td>[user_mention_i'm_nsubj_NN|i'm_i'm_ROOT_VBZ|de...</td>\n",
       "      <td>[user_mention_i'm_nsubj_NN, i'm_i'm_ROOT_VBZ, ...</td>\n",
       "      <td>[user_mention_i'm_nsubjINV, i'm_user_mention_n...</td>\n",
       "      <td>[NN_nsubj_VBZ, VBZ_ROOT_VBZ, JJ_acomp_VBZ, IN_...</td>\n",
       "      <td>[user_mention_nsubj_i'm, i'm_ROOT_i'm, decent_...</td>\n",
       "      <td>[user_mention_i'm_i'm, i'm_i'm_i'm, decent_i'm...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>user_mention I'm decent at editing , no worrie...</td>\n",
       "      <td>[^.^]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>591c29f465419158a43b735f</td>\n",
       "      <td>neither</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[442, 6314, 8, 5114, 3466, 508, 19, 853, 36, 1...</td>\n",
       "      <td>23</td>\n",
       "      <td>[user_mention_read_nsubj_NN|will_read_aux_MD, ...</td>\n",
       "      <td>[user_mention_read_nsubj_NN|will_read_aux_MD|r...</td>\n",
       "      <td>[user_mention_read_nsubj_NN, will_read_aux_MD,...</td>\n",
       "      <td>[user_mention_read_nsubjINV, will_read_auxINV,...</td>\n",
       "      <td>[NN_nsubj_VB, MD_aux_VB, VB_ROOT_VB, NN_aux_VB...</td>\n",
       "      <td>[user_mention_nsubj_read, will_aux_read, read_...</td>\n",
       "      <td>[user_mention_read_read, will_read_read, read_...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>user_mention will read . gotta go afk for a bi...</td>\n",
       "      <td>[afk]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id annotation  avg_token_length  \\\n",
       "0  591c29f465419158a43b735d    neither               4.0   \n",
       "1  591c29f465419158a43b735e    neither               5.0   \n",
       "2  591c29f465419158a43b735f    neither               4.0   \n",
       "\n",
       "                                   brown_cluster_ids  comment_length  \\\n",
       "0  [166, 1914, 12, 5829, 1020, 12, 5098, 20, 5098...              29   \n",
       "1                                [551, 124, 3050, 4]               9   \n",
       "2  [442, 6314, 8, 5114, 3466, 508, 19, 853, 36, 1...              23   \n",
       "\n",
       "                                    feat_dep_bigrams  \\\n",
       "0  [cisco_had_nsubj_NNP|had_allow_aux_VBD, had_al...   \n",
       "1  [user_mention_i'm_nsubj_NN|i'm_i'm_ROOT_VBZ, i...   \n",
       "2  [user_mention_read_nsubj_NN|will_read_aux_MD, ...   \n",
       "\n",
       "                                   feat_dep_trigrams  \\\n",
       "0  [cisco_had_nsubj_NNP|had_allow_aux_VBD|to_deal...   \n",
       "1  [user_mention_i'm_nsubj_NN|i'm_i'm_ROOT_VBZ|de...   \n",
       "2  [user_mention_read_nsubj_NN|will_read_aux_MD|r...   \n",
       "\n",
       "                                   feat_dep_unigrams  \\\n",
       "0  [cisco_had_nsubj_NNP, had_allow_aux_VBD, to_de...   \n",
       "1  [user_mention_i'm_nsubj_NN, i'm_i'm_ROOT_VBZ, ...   \n",
       "2  [user_mention_read_nsubj_NN, will_read_aux_MD,...   \n",
       "\n",
       "                            feat_dependency_contexts  \\\n",
       "0  [cisco_had_nsubjINV, had_cisco_nsubj, had_deal...   \n",
       "1  [user_mention_i'm_nsubjINV, i'm_user_mention_n...   \n",
       "2  [user_mention_read_nsubjINV, will_read_auxINV,...   \n",
       "\n",
       "                                feat_pos_dep_rootPos  \\\n",
       "0  [NNP_nsubj_VBD, VBD_aux_VB, TO_aux_VB, VB_xcom...   \n",
       "1  [NN_nsubj_VBZ, VBZ_ROOT_VBZ, JJ_acomp_VBZ, IN_...   \n",
       "2  [NN_nsubj_VB, MD_aux_VB, VB_ROOT_VB, NN_aux_VB...   \n",
       "\n",
       "                                  feat_word_dep_root  \\\n",
       "0  [cisco_nsubj_had, had_aux_allow, to_aux_deal, ...   \n",
       "1  [user_mention_nsubj_i'm, i'm_ROOT_i'm, decent_...   \n",
       "2  [user_mention_nsubj_read, will_aux_read, read_...   \n",
       "\n",
       "                           feat_word_root_rootparent  has_hs_keywords  \\\n",
       "0  [cisco_had_allow, had_allow_allow, to_deal_had...            False   \n",
       "1  [user_mention_i'm_i'm, i'm_i'm_i'm, decent_i'm...            False   \n",
       "2  [user_mention_read_read, will_read_read, read_...            False   \n",
       "\n",
       "   hs_keyword_count hs_keyword_matches  \\\n",
       "0                 0                 []   \n",
       "1                 0                 []   \n",
       "2                 0                 []   \n",
       "\n",
       "                                                text      unknown_words  \\\n",
       "0  Cisco had to deal with a fat cash payout to th...  [fsf, compliancy]   \n",
       "1  user_mention I'm decent at editing , no worrie...              [^.^]   \n",
       "2  user_mention will read . gotta go afk for a bi...              [afk]   \n",
       "\n",
       "   unknown_words_count  uppercase_token_count  \n",
       "0                    2                      2  \n",
       "1                    1                      0  \n",
       "2                    1                      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_naacl = joblib.load(naacl_2016_persistence)\n",
    "df_nlp = joblib.load(nlp_2016_persistence)\n",
    "df_nlp.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup generic model experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_experiment(X, y, pipeline, process_name, num_expts=1):\n",
    "    scores = list()\n",
    "    for i in tqdm(range(num_expts)):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, train_size=0.80)\n",
    "        model = pipeline.fit(X_train, y_train)  # train the classifier\n",
    "        y_prediction = model.predict(X_test)          # apply the model to the test data\n",
    "        report = classification_report(y_test, y_prediction)\n",
    "        score = accuracy_score(y_prediction, y_test)  # compare the results to the gold standard\n",
    "        scores.append(score)\n",
    "        print(\"Classification Report: \" + process_name)\n",
    "        print(report)\n",
    "        cm = confusion_matrix(y_test, y_prediction)\n",
    "#         print(\"Confusion matrix:\")\n",
    "#         print(cm)\n",
    "#     print(sum(scores) / num_expts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup helpers [GridSearch, numFeatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_gridsearch_cv(pipeline, X, y, param_grid, n_jobs):\n",
    "    grid_search = GridSearchCV(pipeline, param_grid=param_grid, n_jobs=4)\n",
    "    grid_search.fit(X, y)\n",
    "    print(grid_search.best_params_)\n",
    "    print(grid_search.best_score_)\n",
    "    \n",
    "def get_num_features(vectorizer, X):\n",
    "    vect.fit(X)\n",
    "    # feature_names = [feature_names[i] for i in skb.get_support(indices=True)]\n",
    "    return len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive baseline classification (countVectorizer: character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CrowdFlower dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the labels of the test set...\n",
      "14508 documents\n",
      "2 categories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 1/1 [00:22<00:00, 22.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: CrowdFlower: CountVectorizer[character] LSA\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   hatespeech       0.55      0.26      0.35       493\n",
      "not_offensive       0.86      0.96      0.91      2409\n",
      "\n",
      "  avg / total       0.81      0.84      0.81      2902\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_test_set = feat_df.sample(n=int(len(feat_df)), random_state=1965)\n",
    "X = train_test_set['text']\n",
    "y = train_test_set['annotation_label']\n",
    "\n",
    "print(\"Predicting the labels of the test set...\")\n",
    "print(\"%d documents\" % len(X))\n",
    "print(\"%d categories\" % len(y.value_counts()))\n",
    "\n",
    "N_FEATURES_OPTIONS = [100000, 150000]\n",
    "# http://www.kdnuggets.com/2016/08/approaching-almost-any-machine-learning-problem.html/2\n",
    "N_COMPONENTS = [120]\n",
    "n_jobs = 2\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'skb__k': N_FEATURES_OPTIONS,\n",
    "        'svd__n_components': N_COMPONENTS\n",
    "    }\n",
    "]\n",
    "\n",
    "# Params learned through GridSearch\n",
    "k_features = 100000\n",
    "n_components = 120\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(3,5), analyzer='char', stop_words='english')\n",
    "# print(get_num_features(vect, X))\n",
    "\n",
    "clf = LinearSVC()\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "skb = SelectKBest(chi2, k=k_features)\n",
    "\n",
    "count_pipeline = Pipeline([\n",
    "    ('vect', vect),  # extract ngrams from tweet text\n",
    "    ('skb', skb),\n",
    "    ('svd', svd),\n",
    "    ('clf' , clf),   # feed the output through a classifier\n",
    "])\n",
    "\n",
    "# run_gridsearch_cv(count_pipeline, X, y, param_grid, n_jobs)\n",
    "\n",
    "# Run the classifcation\n",
    "run_experiment(X, y, count_pipeline, \"CrowdFlower: CountVectorizer[character] LSA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NAACL 2016 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the labels of the test set...\n",
      "16187 documents\n",
      "3 categories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 1/1 [00:38<00:00, 38.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: NAACL2016: CountVectorizer [character]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none       0.83      0.92      0.87      2233\n",
      "     racism       0.76      0.63      0.69       393\n",
      "     sexism       0.76      0.54      0.63       612\n",
      "\n",
      "avg / total       0.81      0.81      0.81      3238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_test_set = df_naacl.sample(n=int(len(df_naacl)), random_state=1965)\n",
    "X = train_test_set['text']\n",
    "y = train_test_set['annotation']\n",
    "\n",
    "print(\"Predicting the labels of the test set...\")\n",
    "print(\"%d documents\" % len(X))\n",
    "print(\"%d categories\" % len(y.value_counts()))\n",
    "\n",
    "N_FEATURES_OPTIONS = [100000,130000]\n",
    "N_COMPONENTS = [120]\n",
    "n_jobs = 2\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'skb__k': N_FEATURES_OPTIONS,\n",
    "        'svd__n_components': N_COMPONENTS\n",
    "    }\n",
    "]\n",
    "\n",
    "# Params learned through GridSearch\n",
    "k_features = 130000\n",
    "n_components = 120\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(3,5), analyzer='char', stop_words='english')\n",
    "# print(get_num_features(vect, X))\n",
    "\n",
    "clf = LinearSVC()\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "skb = SelectKBest(chi2, k=k_features)\n",
    "\n",
    "count_pipeline = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('skb', skb),\n",
    "    ('svd', svd),\n",
    "    ('clf' , clf),\n",
    "])\n",
    "\n",
    "# run_gridsearch_cv(count_pipeline, X, y, param_grid, n_jobs)\n",
    "run_experiment(X, y, count_pipeline, \"NAACL2016: CountVectorizer [character]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive baseline classification (hashingVectorizer: character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CrowdFlower dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the labels of the test set...\n",
      "14508 documents\n",
      "2 categories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 1/1 [00:03<00:00,  3.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: CrowdFlower: HashingVectorizer[character]\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   hatespeech       0.56      0.35      0.43       473\n",
      "not_offensive       0.88      0.95      0.91      2429\n",
      "\n",
      "  avg / total       0.83      0.85      0.83      2902\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_test_set = feat_df.sample(n=int(len(feat_df)), random_state=1965)\n",
    "X = train_test_set['text']\n",
    "y = train_test_set['annotation_label']\n",
    "\n",
    "print(\"Predicting the labels of the test set...\")\n",
    "print(\"%d documents\" % len(X))\n",
    "print(\"%d categories\" % len(y.value_counts()))\n",
    "\n",
    "vect = HashingVectorizer(ngram_range=(3,5), analyzer='char', stop_words='english')\n",
    "clf = LinearSVC()\n",
    "\n",
    "hashing_pipeline = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('clf' , clf), \n",
    "])\n",
    "run_experiment(X, y, hashing_pipeline, \"CrowdFlower: HashingVectorizer[character]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NAACL 2016 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting the labels of the test set...\n",
      "16187 documents\n",
      "3 categories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 1/1 [00:06<00:00,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: NAACL2016: HashingVectorizer[character]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       none       0.86      0.94      0.90      2217\n",
      "     racism       0.83      0.70      0.76       388\n",
      "     sexism       0.84      0.66      0.74       633\n",
      "\n",
      "avg / total       0.85      0.86      0.85      3238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_test_set = df_naacl.sample(n=int(len(df_naacl)), random_state=1965)\n",
    "X = train_test_set['text']\n",
    "y = train_test_set['annotation']\n",
    "\n",
    "print(\"Predicting the labels of the test set...\")\n",
    "print(\"%d documents\" % len(X))\n",
    "print(\"%d categories\" % len(y.value_counts()))\n",
    "\n",
    "vect = HashingVectorizer(ngram_range=(3,5), analyzer='char')\n",
    "clf = LinearSVC()\n",
    "\n",
    "hashing_pipeline = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('clf' , clf), \n",
    "])\n",
    "run_experiment(X, y, hashing_pipeline, \"NAACL2016: HashingVectorizer[character]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive baseline classification (TfidfVectorizer: character)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CrowdFlower dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train_test_set = feat_df.sample(n=int(len(feat_df)), random_state=1965)\n",
    "X = train_test_set['text']\n",
    "y = train_test_set['annotation_label']\n",
    "\n",
    "print(\"Predicting the labels of the test set...\")\n",
    "print(\"%d documents\" % len(X))\n",
    "print(\"%d categories\" % len(y.value_counts()))\n",
    "\n",
    "N_FEATURES_OPTIONS = [100000, 200000]\n",
    "N_COMPONENTS = [120]\n",
    "n_jobs = 2\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'skb__k': N_FEATURES_OPTIONS,\n",
    "        'svd__n_components': N_COMPONENTS\n",
    "    }\n",
    "]\n",
    "\n",
    "# Params learned through GridSearch\n",
    "k_features = 150000\n",
    "n_components = 120\n",
    "\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "skb = SelectKBest(chi2, k=k_features)\n",
    "vect = TfidfVectorizer(ngram_range=(3,5), analyzer='char', stop_words='english')\n",
    "# print(get_num_features(vect, X))\n",
    "\n",
    "clf = LinearSVC()\n",
    "\n",
    "tfidf_pipeline = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('skb', skb),\n",
    "    ('svd', svd),\n",
    "    ('clf' , clf),\n",
    "])\n",
    "\n",
    "# run_gridsearch_cv(tfidf_pipeline, X, y, param_grid, n_jobs)\n",
    "run_experiment(X, y, tfidf_pipeline, \"CrowdFlower: LSA - TfidfVectorizer[character]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NAACL 2016 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set = df_naacl.sample(n=int(len(df_naacl)), random_state=1965)\n",
    "X = train_test_set['text']\n",
    "y = train_test_set['annotation']\n",
    "\n",
    "print(\"Predicting the labels of the test set...\")\n",
    "print(\"%d documents\" % len(X))\n",
    "print(\"%d categories\" % len(y.value_counts()))\n",
    "\n",
    "N_FEATURES_OPTIONS = [100000, 200000]\n",
    "N_COMPONENTS = [120]\n",
    "n_jobs = 2\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'skb__k': N_FEATURES_OPTIONS,\n",
    "        'svd__n_components': N_COMPONENTS\n",
    "    }\n",
    "]\n",
    "\n",
    "# Params learned through GridSearch\n",
    "k_features = 150000\n",
    "n_components = 120\n",
    "\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "skb = SelectKBest(chi2, k=k_features)\n",
    "vect = TfidfVectorizer(ngram_range=(3,5), analyzer='char', stop_words='english')\n",
    "# print(get_num_features(vect, X))\n",
    "\n",
    "clf = LinearSVC()\n",
    "tfidf_pipeline = Pipeline([\n",
    "    ('vect', vect),\n",
    "    ('skb', skb),\n",
    "#     ('svd', svd),\n",
    "    ('clf' , clf),\n",
    "])\n",
    "\n",
    "# run_gridsearch_cv(tfidf_pipeline, X, y, param_grid, n_jobs)\n",
    "run_experiment(X, y, tfidf_pipeline, \"NAACL2016: TfidfVectorizer[character]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency tuple experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set = feat_df.sample(n=int(len(feat_df)), random_state=1965)\n",
    "X = train_test_set['feat_word_root_rootparent']\n",
    "y = train_test_set['annotation_label']\n",
    "\n",
    "hasher = FeatureHasher(input_type='string', non_negative=True)\n",
    "clf = LinearSVC()\n",
    "\n",
    "featurer_hasher_pipeline = Pipeline([\n",
    "    ('hasher', hasher),\n",
    "    ('clf' , clf),\n",
    "])\n",
    "run_experiment(X, y, featurer_hasher_pipeline, \"CrowdFlower: FeatureHasher\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Unions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup column extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TextExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Adapted from code by @zacstewart \n",
    "       https://github.com/zacstewart/kaggle_seeclickfix/blob/master/estimator.py\n",
    "       Also see Zac Stewart's excellent blogpost on pipelines:\n",
    "       http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html\n",
    "       \"\"\"\n",
    "    \n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name\n",
    "\n",
    "    def transform(self, df):\n",
    "        # select the relevant column and return it as a numpy array\n",
    "        # set the array type to be string\n",
    "        return np.asarray(df[self.column_name]).astype(str)\n",
    "        \n",
    "    def fit(self, *_):\n",
    "        return self\n",
    "\n",
    "class TextListExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name\n",
    "    \n",
    "    def transform(self, df):\n",
    "        return df[self.column_name].tolist()\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self    \n",
    "\n",
    "class Apply(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Applies a function f element-wise to the numpy array\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, fn):\n",
    "        self.fn = np.vectorize(fn)\n",
    "        \n",
    "    def transform(self, data):\n",
    "        # note: reshaping is necessary because otherwise sklearn\n",
    "        # interprets 1-d array as a single sample\n",
    "        return self.fn(data.reshape(data.size, 1))\n",
    "\n",
    "    def fit(self, *_):\n",
    "        return self\n",
    "    \n",
    "class BooleanExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, column_name):\n",
    "        self.column_name = column_name\n",
    "\n",
    "    def transform(self, df):\n",
    "        # select the relevant column and return it as a numpy array\n",
    "        # set the array type to be string\n",
    "        return np.asarray(df[self.column_name]).astype(np.int)\n",
    "                                                       \n",
    "    def fit(self, *_):\n",
    "        return self\n",
    "\n",
    "empty_analyzer = lambda x: x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_set = df_naacl.sample(n=int(len(feat_df)), random_state=1965)\n",
    "X = train_test_set[['text', 'feat_dependency_contexts', 'hs_keyword_count']]\n",
    "y = train_test_set['annotation']\n",
    "clf = LinearSVC()\n",
    "\n",
    "# Setup char ngram pipeline\n",
    "k_features = 150000\n",
    "char_skb = SelectKBest(chi2, k=k_features)\n",
    "char_vect = TfidfVectorizer(ngram_range=(3,5), analyzer='char', stop_words='english')\n",
    "char_tfidf_pipeline = Pipeline([\n",
    "    ('text_extractor', TextExtractor('text')),\n",
    "    ('char_vect', char_vect),\n",
    "    ('skb', char_skb)\n",
    "])\n",
    "\n",
    "# Setup feature tf-idf vectorizer\n",
    "dep_context_vect = TfidfVectorizer(analyzer=empty_analyzer)\n",
    "dependency_context_pipeline = Pipeline([\n",
    "    ('dep_extractor', TextListExtractor('feat_dependency_contexts')), # extract names from df\n",
    "    ('dep_context_vect', dep_context_vect)\n",
    "])\n",
    "\n",
    "\n",
    "hs_keyword_count_pipeline = Pipeline([\n",
    "    ('count_extractor', BooleanExtractor('hs_keyword_count')),\n",
    "    ('identity', Apply(lambda x: x))\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('all_features', FeatureUnion([\n",
    "        ('char_tfidf_pipeline', char_tfidf_pipeline),\n",
    "        ('dependency_context_pipeline', dependency_context_pipeline),\n",
    "        ('hs_keyword_count_pipeline', hs_keyword_count_pipeline),\n",
    "    ])),\n",
    "    ('clf' , clf),\n",
    "])\n",
    "\n",
    "run_experiment(X, y, pipeline, \"TfidfVectorizer\")\n",
    "\n",
    "# https://github.com/michelleful/SingaporeRoadnameOrigins/blob/master/notebooks/04%20Adding%20features%20with%20Pipelines.ipynb\n",
    "# https://github.com/amueller/kaggle_insults/blob/e4abac805be1d1e2b3201a978172bafd36cc01e3/features.py\n",
    "# http://www.markhneedham.com/blog/2015/03/02/python-scikit-learn-training-a-classifier-with-non-numeric-features/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
