{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding Comparisons [dependency2vec vs word2vec]\n",
    "\n",
    "This is a staging notebook for testing the models produced by the different word embedding approaches being considered, word2vec and dependency2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from gensim import models, similarities\n",
    "from tqdm import tqdm\n",
    "from modules.utils.CustomTwokenizer import CustomTwokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spacy_en_model = \"en_core_web_md\"\n",
    "spacy_glove_model = \"en_vectors_glove_md\"\n",
    "crowdflower_persistence_raw = 'data/persistence/df/crowdflower_features_raw.pkl.compressed'\n",
    "crowdflower_persistence = 'data/persistence/df/crowdflower_features.pkl.compressed'\n",
    "nlp = spacy.load(spacy_en_model, create_make_doc=CustomTwokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar(word, n):\n",
    "    queries = [w for w in word.vocab if not (word.is_oov or word.is_punct or word.like_num or word.is_stop or word.lower_ == \"rt\") and w.has_vector and w.lower_ != word.lower_ and w.is_lower == word.is_lower and w.prob >= -15]\n",
    "    by_similarity = sorted(queries, key=lambda w: word.similarity(w), reverse=True)\n",
    "    cosine_score = [word.similarity(w) for w in by_similarity]\n",
    "    return by_similarity[:n], cosine_score[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and test dependency2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hatespeech_dep_word = \"data/persistence/df/dim200vecs_hatespeech_dep\"\n",
    "hs_candidates_exp6_word = \"data/persistence/df/dim200vecs_hs_candidates_exp6\"\n",
    "hatespeech_dep_context = \"data/persistence/df/dim200context-vecs_hatespeech_dep\"\n",
    "hs_candidates_exp6_context = \"data/persistence/df/dim200context-vecs_hs_candidates_exp6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hatespeech_model = models.KeyedVectors.load_word2vec_format(hatespeech_dep_word, binary=False)\n",
    "hs_candidates_exp6_model = models.KeyedVectors.load_word2vec_format(hs_candidates_exp6_word, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('wetbacks', 0.9985026717185974),\n",
       " ('something', 0.9980785846710205),\n",
       " ('nothing', 0.9980483055114746),\n",
       " ('chinks', 0.9975727796554565),\n",
       " ('dumb', 0.9975383281707764),\n",
       " ('stupid', 0.9971219301223755),\n",
       " ('nice', 0.9970505833625793),\n",
       " ('mouth', 0.9969522953033447),\n",
       " ('birthday', 0.9969327449798584),\n",
       " (\"they're\", 0.9969197511672974),\n",
       " ('ok', 0.9969000816345215),\n",
       " ('wallet', 0.9968050122261047),\n",
       " (\"what's\", 0.996655285358429),\n",
       " ('whites', 0.9965375661849976),\n",
       " ('gonna', 0.9962338209152222),\n",
       " ('ppl', 0.9962177276611328),\n",
       " ('cuz', 0.9960685968399048),\n",
       " ('wrong', 0.9960306882858276),\n",
       " ('also', 0.9955644607543945),\n",
       " ('beautiful', 0.9955433011054993)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hatespeech_model.similar_by_word(\"savages\", topn=20, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.68546251287656113"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hs_candidates_exp6_model.most_similar(positive=['nigger'], negative=['smart'], topn=15)\n",
    "hs_candidates_exp6_model.similarity('savages', 'muslim')\n",
    "# hs_candidates_exp6_model.similar_by_word(\"savage\", topn=20, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74220567500300816"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(hs_candidates_exp6_model.vocab.keys())\n",
    "len(vocab)\n",
    "hs_candidates_exp6_model.similarity('woman', 'man')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and test word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word = nlp.vocab[u'bitches']\n",
    "gloVe_result = most_similar(word, 20)\n",
    "for res in zip(gloVe_result[0], gloVe_result[1]):\n",
    "    print((res[0].lower_, res[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize model\n",
    "https://github.com/jeffThompson/Word2VecAndTsne\n",
    "\n",
    "https://www.quora.com/How-do-I-visualise-word2vec-word-vectors"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
