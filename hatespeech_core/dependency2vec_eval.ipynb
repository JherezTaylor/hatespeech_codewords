{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency2vec code word identification\n",
    "\n",
    "We experiment with methods for evaluating code words based on average cosine similarity and traditional word embeddings\n",
    "\n",
    "- See issue [#85](https://github.com/JherezTaylor/thesis-preprocessing/issues/85) and [#91](https://github.com/JherezTaylor/thesis-preprocessing/issues/91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob, os\n",
    "from pprint import pprint\n",
    "import joblib\n",
    "import pandas\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm\n",
    "from modules.db import elasticsearch_base\n",
    "from modules.preprocessing import neural_embeddings\n",
    "from modules.utils import file_ops, model_helpers, settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize params and objects\n",
    "\n",
    "Here we define common functions for loading our embeddings and extracting the vocabulary and vocabulary counts. ft_word_embeddings and w2v_word_embeddings each store a list of references to embedding models that exist on disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_raw_vocab(df):\n",
    "    vect = CountVectorizer(analyzer='word', stop_words='english')\n",
    "    X = df[\"text\"]\n",
    "    fit_result = vect.fit(X)\n",
    "    vocabulary = fit_result.vocabulary_\n",
    "    return len(vocabulary), vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dim200vecs_dstormer_conll\n",
      "1 dim200vecs_hs_candidates_exp6\n",
      "2 dim200vecs_inaug_conll\n",
      "3 dim200vecs_manch_conll\n",
      "4 dim200vecs_melvynhs_conll\n",
      "5 dim200vecs_twitter_conll\n",
      "6 dim200vecs_uselec_conll\n",
      "7 dim200vecs_ustream_conll\n"
     ]
    }
   ],
   "source": [
    "embeddings = neural_embeddings.get_embeddings(\"kv\", model_ids=[5,0,7,3,4], load=True)\n",
    "if embeddings:\n",
    "    dep2vec_twitter = embeddings[0] \n",
    "    dep2vec_dstormer = embeddings[1]\n",
    "    dep2vec_ustream = embeddings[2]\n",
    "    dep2vec_manchester = embeddings[3]\n",
    "    dep2vec_melvyn_hs = embeddings[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataframes and other objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_es = elasticsearch_base.connect(settings.ES_URL)\n",
    "# df_naacl = joblib.load(settings.NAACL_2016_DATA)\n",
    "# df_nlp = joblib.load(settings.NLP_2016_DATA)\n",
    "# df_crwdflr = joblib.load(settings.CRWDFLR_DATA)\n",
    "\n",
    "hs_keywords = set(file_ops.read_csv_file(\"hate_1\", settings.TWITTER_SEARCH_PATH) +\n",
    "              file_ops.read_csv_file(\"hate_2\", settings.TWITTER_SEARCH_PATH) +\n",
    "              file_ops.read_csv_file(\"hate_3\", settings.TWITTER_SEARCH_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get to work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get word frequencies from corpuses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manchester event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manchester tweet count: 617698\n"
     ]
    }
   ],
   "source": [
    "result = elasticsearch_base.aggregate(_es, \"manchester_event\", \"tokens.keyword\", False, size=100000, min_doc_count=5)\n",
    "print(\"Manchester tweet count: {0}\".format(result[1]))\n",
    "manchester_hs, manchester_vocab = model_helpers.get_els_word_probabilities(result[0], result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'22.05.17': 6e-05,\n",
      " 'abbot': 5e-05,\n",
      " 'absurdly': 4e-05,\n",
      " 'activist': 8e-05,\n",
      " 'addresses': 0.00046,\n",
      " 'amendment': 5e-05,\n",
      " 'anxious': 0.00013,\n",
      " 'asleep': 8e-05,\n",
      " 'asshole': 0.00026,\n",
      " 'axe': 6e-05,\n",
      " 'background': 0.00031,\n",
      " 'banksy': 2e-05,\n",
      " 'barackâ€™s': 9e-05,\n",
      " 'barbershop': 0.00014,\n",
      " 'bastard': 0.00029,\n",
      " 'bearing': 2e-05,\n",
      " 'billionaire': 0.00019,\n",
      " 'bitch': 0.00066,\n",
      " 'bleeds': 6e-05,\n",
      " 'blocks': 6e-05,\n",
      " 'boy': 0.00134,\n",
      " 'brunch': 4e-05,\n",
      " 'bryan': 0.00014,\n",
      " 'bull': 0.0001,\n",
      " 'bullies': 3e-05,\n",
      " 'cake': 0.00016,\n",
      " 'catastrophic': 3e-05,\n",
      " 'chick': 0.0001,\n",
      " 'choice': 0.00051,\n",
      " 'clips': 6e-05,\n",
      " 'coalition': 0.0001,\n",
      " 'com': 0.00119,\n",
      " 'comfortable': 8e-05,\n",
      " 'comp': 4e-05,\n",
      " 'congratulations': 0.00066,\n",
      " 'consolation': 2e-05,\n",
      " 'convenient': 8e-05,\n",
      " 'corbyns': 6e-05,\n",
      " 'couldnt': 9e-05,\n",
      " 'creature': 4e-05,\n",
      " 'cuck': 8e-05,\n",
      " 'culpable': 4e-05,\n",
      " 'cunt': 0.00066,\n",
      " 'dave': 0.00013,\n",
      " 'dealings': 6e-05,\n",
      " 'dean': 0.0002,\n",
      " 'delays': 0.00015,\n",
      " 'dementia': 8e-05,\n",
      " 'democrat': 0.00011,\n",
      " 'deranged': 5e-05,\n",
      " 'dj': 0.00032,\n",
      " 'doubt': 0.0016,\n",
      " 'dr.': 0.00013,\n",
      " 'drafting': 5e-05,\n",
      " 'drum': 7e-05,\n",
      " 'effect': 0.00035,\n",
      " 'emma': 5e-05,\n",
      " 'empty': 0.00013,\n",
      " 'equal': 0.00011,\n",
      " 'establishment': 0.00036,\n",
      " 'ex': 0.00039,\n",
      " 'explodes': 9e-05,\n",
      " 'fabregas': 0.00012,\n",
      " 'fear': 0.00309,\n",
      " 'fool': 0.0004,\n",
      " 'fortress': 2e-05,\n",
      " 'fortunate': 9e-05,\n",
      " 'fuss': 4e-05,\n",
      " 'gingrich': 9e-05,\n",
      " 'gop': 0.00014,\n",
      " 'gosh': 0.00014,\n",
      " 'hazard': 6e-05,\n",
      " 'heartless': 0.00015,\n",
      " 'hesitation': 1e-05,\n",
      " 'idiot': 0.00113,\n",
      " 'ill': 0.00028,\n",
      " 'importance': 0.00014,\n",
      " 'ins': 0.00013,\n",
      " 'ironic': 0.00014,\n",
      " 'isnâ€™t': 7e-05,\n",
      " 'jack': 0.0002,\n",
      " 'jane': 0.00019,\n",
      " 'jazeera': 6e-05,\n",
      " 'jus': 9e-05,\n",
      " 'kevin': 0.00016,\n",
      " 'law': 0.00102,\n",
      " 'lazy': 0.0001,\n",
      " 'lennon': 8e-05,\n",
      " 'levy': 5e-05,\n",
      " 'liability': 4e-05,\n",
      " 'lie': 0.00072,\n",
      " 'lights': 0.00016,\n",
      " 'longfella': 0.00015,\n",
      " 'loyal': 7e-05,\n",
      " 'lucy': 0.00015,\n",
      " 'm15': 8e-05,\n",
      " 'mad': 0.00101,\n",
      " 'mans': 0.00015,\n",
      " 'mehdi': 1e-05,\n",
      " 'michelle': 0.00018,\n",
      " 'minded': 7e-05,\n",
      " 'morrison': 1e-05,\n",
      " 'murphy': 6e-05,\n",
      " 'naive': 0.00011,\n",
      " 'negativity': 2e-05,\n",
      " 'newsround': 1e-05,\n",
      " 'numb': 6e-05,\n",
      " 'obituaries': 0.00017,\n",
      " 'pereira': 0.00014,\n",
      " 'perez': 2e-05,\n",
      " 'pink': 0.0003,\n",
      " 'predictable': 6e-05,\n",
      " 'prick': 0.00025,\n",
      " 'prince': 0.00274,\n",
      " 'principal': 2e-05,\n",
      " 'properties': 0.0001,\n",
      " 'psychiatry': 0.00014,\n",
      " 'rap': 0.0001,\n",
      " 'reason': 0.00207,\n",
      " 'refreshments': 1e-05,\n",
      " 'regulation': 8e-05,\n",
      " 'respect': 0.00432,\n",
      " 'richard': 0.00017,\n",
      " 'scumbag': 0.00022,\n",
      " 'shame': 0.00176,\n",
      " 'simplicity': 7e-05,\n",
      " \"something's\": 3e-05,\n",
      " 'spots': 3e-05,\n",
      " 'strootman': 0.00016,\n",
      " 'surge': 0.00024,\n",
      " 'takers': 6e-05,\n",
      " 'tape': 3e-05,\n",
      " 'ther': 8e-05,\n",
      " 'tolerant': 0.00011,\n",
      " 'tosser': 4e-05,\n",
      " 'tucker': 0.00025,\n",
      " 'tuned': 4e-05,\n",
      " 'twat': 0.00033,\n",
      " 'u.k.': 0.00453,\n",
      " 'uber': 7e-05,\n",
      " 'uk': 0.03974,\n",
      " 'ukâ€™s': 0.00063,\n",
      " 'uneducated': 6e-05,\n",
      " 'upset': 0.00096,\n",
      " 'vigilant': 0.00021,\n",
      " 'virus': 2e-05,\n",
      " 'vocal': 5e-05,\n",
      " 'whoâ€™s': 2e-05,\n",
      " 'wi': 0.00027,\n",
      " 'wishes': 0.00031,\n",
      " 'wor': 9e-05,\n",
      " 'words': 0.00403,\n",
      " 'world': 0.01067,\n",
      " 'ðŸ”¥ðŸ”¥ðŸ”¥ðŸ”¥': 2e-05}\n"
     ]
    }
   ],
   "source": [
    "candidate_codewords = model_helpers.select_candidate_codewords(dep2vec_manchester, manchester_vocab, hs_keywords)\n",
    "pprint(candidate_codewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'abou': 7e-05,\n",
      " 'academic': 5e-05,\n",
      " 'accident': 0.00019,\n",
      " 'agai': 2e-05,\n",
      " 'alpha': 1e-05,\n",
      " 'alternate': 3e-05,\n",
      " 'animal': 0.0001,\n",
      " 'ape': 2e-05,\n",
      " 'aryan': 1e-05,\n",
      " 'asshat': 3e-05,\n",
      " 'asshole': 0.00026,\n",
      " 'atheist': 4e-05,\n",
      " 'author': 0.00013,\n",
      " 'bait': 5e-05,\n",
      " 'bastard': 0.00029,\n",
      " 'battery': 0.00039,\n",
      " 'bigot': 8e-05,\n",
      " 'bird': 7e-05,\n",
      " 'bitch': 0.00066,\n",
      " 'blonde': 6e-05,\n",
      " 'bonus': 0.00011,\n",
      " 'boot': 9e-05,\n",
      " 'boring': 0.0002,\n",
      " 'bounty': 1e-05,\n",
      " 'brush': 3e-05,\n",
      " 'buffoon': 6e-05,\n",
      " 'bull': 0.0001,\n",
      " 'bureau': 1e-05,\n",
      " 'burger': 4e-05,\n",
      " 'busy': 0.00067,\n",
      " 'celeb': 0.00011,\n",
      " 'celebrity': 0.00029,\n",
      " 'changer': 2e-05,\n",
      " 'chicken': 9e-05,\n",
      " 'classroom': 1e-05,\n",
      " 'clock': 0.00017,\n",
      " 'coincidence': 0.00019,\n",
      " 'collective': 0.00011,\n",
      " 'comedy': 0.00022,\n",
      " 'commie': 3e-05,\n",
      " 'complex': 0.00014,\n",
      " 'cooler': 2e-05,\n",
      " 'cow': 0.00018,\n",
      " 'crazy': 0.00087,\n",
      " 'creed': 2e-05,\n",
      " 'cuck': 8e-05,\n",
      " 'cunt': 0.00066,\n",
      " 'dan': 0.00044,\n",
      " 'dance': 0.00039,\n",
      " 'dawn': 0.00031,\n",
      " 'dea': 5e-05,\n",
      " 'delay': 0.00011,\n",
      " 'dictionary': 1e-05,\n",
      " 'disease': 6e-05,\n",
      " 'drug': 0.00013,\n",
      " 'drum': 7e-05,\n",
      " 'dumbass': 0.00016,\n",
      " 'dummy': 4e-05,\n",
      " 'edgy': 3e-05,\n",
      " 'elect': 0.0002,\n",
      " 'elephant': 0.0001,\n",
      " 'emperor': 1e-05,\n",
      " 'enemy': 0.00054,\n",
      " 'f*ck': 5e-05,\n",
      " 'faggot': 5e-05,\n",
      " 'farmer': 2e-05,\n",
      " 'fever': 4e-05,\n",
      " 'frog': 2e-05,\n",
      " 'fry': 1e-05,\n",
      " 'gag': 1e-05,\n",
      " 'generation': 0.00022,\n",
      " 'genius': 0.00012,\n",
      " 'gi': 4e-05,\n",
      " 'giant': 0.0001,\n",
      " 'gifted': 2e-05,\n",
      " 'globalist': 0.00015,\n",
      " 'goy': 1e-05,\n",
      " 'greek': 2e-05,\n",
      " 'hardest': 6e-05,\n",
      " 'hater': 6e-05,\n",
      " 'homeland': 0.00057,\n",
      " 'hyde': 0.00014,\n",
      " 'idiot': 0.00113,\n",
      " 'ignorant': 0.00044,\n",
      " 'increase': 0.00043,\n",
      " 'infidel': 6e-05,\n",
      " 'insane': 0.00042,\n",
      " 'jack': 0.0002,\n",
      " 'jackass': 4e-05,\n",
      " 'jew': 0.00014,\n",
      " 'joke': 0.00117,\n",
      " 'jordan': 0.00013,\n",
      " 'junior': 0.00012,\n",
      " 'lad': 0.00053,\n",
      " 'latin': 3e-05,\n",
      " 'liar': 0.00023,\n",
      " 'lib': 0.00029,\n",
      " 'libtard': 5e-05,\n",
      " 'lincoln': 9e-05,\n",
      " 'lord': 0.00045,\n",
      " 'lucky': 0.00048,\n",
      " 'lunatic': 8e-05,\n",
      " 'masked': 9e-05,\n",
      " 'menace': 3e-05,\n",
      " 'mensch': 1e-05,\n",
      " 'mere': 5e-05,\n",
      " 'millionaire': 7e-05,\n",
      " 'mistake': 0.00032,\n",
      " 'mix': 0.00059,\n",
      " 'monster': 0.00022,\n",
      " 'moron': 0.00039,\n",
      " 'motherfucker': 3e-05,\n",
      " 'muhammad': 0.00018,\n",
      " 'muppet': 6e-05,\n",
      " 'muscle': 4e-05,\n",
      " 'musical': 0.00015,\n",
      " 'na': 0.00026,\n",
      " 'narcissist': 2e-05,\n",
      " 'nationwide': 7e-05,\n",
      " 'nazi': 0.00015,\n",
      " 'negotiation': 1e-05,\n",
      " 'neighborhood': 0.0002,\n",
      " 'neocon': 1e-05,\n",
      " 'nexus': 1e-05,\n",
      " 'nigerian': 0.00134,\n",
      " 'nigga': 0.00025,\n",
      " 'nigger': 1e-05,\n",
      " 'op': 0.00014,\n",
      " 'parasite': 2e-05,\n",
      " 'perverted': 5e-05,\n",
      " 'phobia': 7e-05,\n",
      " 'pickup': 5e-05,\n",
      " 'pig': 0.00012,\n",
      " 'pl': 0.00038,\n",
      " 'pony': 1e-05,\n",
      " 'pos': 0.00017,\n",
      " 'pow': 4e-05,\n",
      " 'prick': 0.00025,\n",
      " 'pussy': 9e-05,\n",
      " 'rapper': 0.00021,\n",
      " 'rat': 0.00011,\n",
      " 'ratio': 2e-05,\n",
      " 'realist': 1e-05,\n",
      " 'rebel': 0.00023,\n",
      " 'redneck': 9e-05,\n",
      " 'regional': 0.00012,\n",
      " 'repeat': 0.0002,\n",
      " 'retard': 7e-05,\n",
      " 'saga': 3e-05,\n",
      " 'sanctuary': 5e-05,\n",
      " 'shark': 1e-05,\n",
      " 'shed': 0.0002,\n",
      " 'shift': 0.00026,\n",
      " 'shit': 0.00329,\n",
      " 'sicko': 3e-05,\n",
      " 'sjw': 2e-05,\n",
      " 'slain': 3e-05,\n",
      " 'slut': 3e-05,\n",
      " 'snap': 0.00026,\n",
      " 'snowden': 2e-05,\n",
      " 'snowflake': 6e-05,\n",
      " 'spoiled': 5e-05,\n",
      " 'surge': 0.00024,\n",
      " 'surprise': 0.00081,\n",
      " 'sweetheart': 0.00021,\n",
      " 'tel': 0.00017,\n",
      " 'tho': 0.00072,\n",
      " 'tide': 4e-05,\n",
      " 'tier': 1e-05,\n",
      " 'toilet': 7e-05,\n",
      " 'toy': 3e-05,\n",
      " 'trojan': 2e-05,\n",
      " 'twat': 0.00033,\n",
      " 'twin': 0.0001,\n",
      " 'unverified': 1e-05,\n",
      " 'vegan': 6e-05,\n",
      " 'viking': 1e-05,\n",
      " 'virgin': 0.0001,\n",
      " 'virus': 2e-05,\n",
      " 'wheel': 3e-05,\n",
      " 'whore': 5e-05,\n",
      " 'williams': 0.00066,\n",
      " 'wind': 0.00054,\n",
      " 'winds': 3e-05,\n",
      " 'witch': 0.00013}\n"
     ]
    }
   ],
   "source": [
    "candidate_codewords = model_helpers.select_candidate_codewords(dep2vec_melvyn_hs, manchester_vocab, hs_keywords)\n",
    "pprint(candidate_codewords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dailystormer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dailystormer document count: 26015\n",
      "{'ape': 0.00023,\n",
      " 'apple': 0.00027,\n",
      " 'bitch': 0.00062,\n",
      " 'faggot': 0.00023,\n",
      " 'guinea': 0.00019,\n",
      " 'idiot': 0.00023,\n",
      " 'kike': 0.0005,\n",
      " 'monkey': 0.00031,\n",
      " 'negro': 0.00104,\n",
      " 'nigger': 0.00027,\n",
      " 'property': 0.00092,\n",
      " 'pussy': 0.00019,\n",
      " 'queen': 0.00023,\n",
      " 'retarded': 0.00027,\n",
      " 'whitey': 0.00023}\n"
     ]
    }
   ],
   "source": [
    "result = elasticsearch_base.aggregate(_es, \"dailystormer\", \"tokens.keyword\", False, size=10000, min_doc_count=5)\n",
    "print(\"Dailystormer document count: {0}\".format(result[1]))\n",
    "dailystormer_hs, dailystormer_vocab = model_helpers.get_els_word_probabilities(result[0], result[1])\n",
    "pprint(dailystormer_hs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### melvyn_hs_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melvyn HS tweet count: 328627\n",
      "0.00119\n"
     ]
    }
   ],
   "source": [
    "result = elasticsearch_base.aggregate(_es, \"melvyn_hs\", \"tokens.keyword\", False, size=15000, min_doc_count=5)\n",
    "print(\"Melvyn HS tweet count: {0}\".format(result[1]))\n",
    "melvyn_users_hs, melvyn_hs_vocab = model_helpers.get_els_word_probabilities(result[0], result[1])\n",
    "pprint(melvyn_hs_vocab['faggot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unfiltered_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfiltered stream tweet count: 3241381\n",
      "6e-05\n"
     ]
    }
   ],
   "source": [
    "result = elasticsearch_base.aggregate(_es, \"unfiltered_stream\", \"tokens.keyword\", False, size=15000, min_doc_count=10)\n",
    "print(\"Unfiltered stream tweet count: {0}\".format(result[1]))\n",
    "unfiltered_stream_hs, unfiltered_stream_vocab = model_helpers.get_els_word_probabilities(result[0], result[1])\n",
    "pprint(unfiltered_stream_vocab['faggot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### core_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core_tweets tweet count: 6843555\n",
      "{'abo': 0.00019,\n",
      " 'af': 0.02696,\n",
      " 'albino': 0.00032,\n",
      " 'ape': 0.00105,\n",
      " 'apple': 0.02184,\n",
      " 'azn': 3e-05,\n",
      " 'banana': 0.00292,\n",
      " 'beaner': 8e-05,\n",
      " 'bint': 5e-05,\n",
      " 'bird': 0.00616,\n",
      " 'bitch': 0.05996,\n",
      " 'blockhead': 3e-05,\n",
      " 'bogan': 4e-05,\n",
      " 'bong': 0.00061,\n",
      " 'boo': 0.01058,\n",
      " 'boon': 0.00026,\n",
      " 'boong': 5e-05,\n",
      " 'brownie': 0.00069,\n",
      " 'bubble': 0.004,\n",
      " 'buck': 0.00191,\n",
      " 'buffie': 4e-05,\n",
      " 'bumblebee': 0.00011,\n",
      " 'bung': 4e-05,\n",
      " 'bunga': 4e-05,\n",
      " 'celestial': 0.00025,\n",
      " 'chav': 0.00015,\n",
      " 'chink': 0.0001,\n",
      " 'chug': 0.00025,\n",
      " 'chunky': 0.00118,\n",
      " 'clam': 0.00025,\n",
      " 'cocoa': 0.00083,\n",
      " 'coconut': 0.00183,\n",
      " 'colored': 0.00141,\n",
      " 'coloured': 0.0005,\n",
      " 'coolie': 2e-05,\n",
      " 'coon': 0.00047,\n",
      " 'cracker': 0.00096,\n",
      " 'cripple': 0.00018,\n",
      " 'crow': 0.00118,\n",
      " 'cunt': 0.00559,\n",
      " 'dago': 2e-05,\n",
      " 'dink': 8e-05,\n",
      " 'div': 0.00056,\n",
      " 'divvy': 3e-05,\n",
      " 'domes': 4e-05,\n",
      " 'dyke': 0.00042,\n",
      " 'egg': 0.0046,\n",
      " 'eggplant': 0.0002,\n",
      " 'fag': 0.00074,\n",
      " 'faggot': 0.0015,\n",
      " 'fez': 0.00011,\n",
      " 'frog': 0.00163,\n",
      " 'fruit': 0.00398,\n",
      " 'fuzzy': 0.0011,\n",
      " 'gable': 8e-05,\n",
      " 'gew': 3e-05,\n",
      " 'ghetto': 0.00154,\n",
      " 'ghost': 0.00738,\n",
      " 'gin': 0.00102,\n",
      " 'ginger': 0.00203,\n",
      " 'gook': 0.00013,\n",
      " 'greaser': 6e-05,\n",
      " 'guala': 3e-05,\n",
      " 'gub': 2e-05,\n",
      " 'guido': 0.00018,\n",
      " 'guinea': 0.00132,\n",
      " 'gyp': 3e-05,\n",
      " 'hayseed': 2e-05,\n",
      " 'hebe': 3e-05,\n",
      " 'hick': 0.00034,\n",
      " 'ho': 0.01436,\n",
      " 'hoe': 0.02714,\n",
      " 'honkey': 6e-05,\n",
      " 'honky': 0.00028,\n",
      " 'hoosier': 0.00028,\n",
      " 'hoser': 3e-05,\n",
      " 'idiot': 0.02434,\n",
      " 'ike': 0.00111,\n",
      " 'iky': 3e-05,\n",
      " 'jig': 0.00057,\n",
      " 'jigg': 3e-05,\n",
      " 'jigga': 0.00018,\n",
      " 'jiggaboo': 3e-05,\n",
      " 'jigger': 6e-05,\n",
      " 'khazar': 2e-05,\n",
      " 'kike': 0.00023,\n",
      " 'knacker': 2e-05,\n",
      " 'kraut': 8e-05,\n",
      " 'lefty': 0.00164,\n",
      " 'leprechaun': 0.00021,\n",
      " 'limey': 6e-05,\n",
      " 'mack': 0.00206,\n",
      " 'mick': 0.00187,\n",
      " 'mickey': 0.00497,\n",
      " 'millie': 0.00083,\n",
      " 'moch': 4e-05,\n",
      " 'mock': 0.00361,\n",
      " 'moke': 5e-05,\n",
      " 'mong': 0.00055,\n",
      " 'monkey': 0.00824,\n",
      " 'moxy': 4e-05,\n",
      " 'muk': 0.00017,\n",
      " 'mulato': 2e-05,\n",
      " 'mung': 5e-05,\n",
      " 'munt': 5e-05,\n",
      " 'munter': 2e-05,\n",
      " 'mutt': 0.00036,\n",
      " 'muzzie': 6e-05,\n",
      " 'nacho': 0.00084,\n",
      " 'ned': 0.00086,\n",
      " 'negro': 0.00145,\n",
      " 'nicca': 0.00021,\n",
      " 'nig': 0.00086,\n",
      " 'nigar': 3e-05,\n",
      " 'niger': 0.00161,\n",
      " 'niggar': 3e-05,\n",
      " 'nigger': 0.00292,\n",
      " 'nigglet': 2e-05,\n",
      " 'niglet': 3e-05,\n",
      " 'nigra': 2e-05,\n",
      " 'nip': 0.00193,\n",
      " 'paddy': 0.00126,\n",
      " 'paki': 0.00105,\n",
      " 'pancake': 0.00138,\n",
      " 'papoose': 0.00018,\n",
      " 'pikey': 0.0001,\n",
      " 'pinto': 0.00035,\n",
      " 'pogue': 2e-05,\n",
      " 'pollo': 0.0002,\n",
      " 'pom': 0.00063,\n",
      " 'prod': 0.01661,\n",
      " 'property': 0.00941,\n",
      " 'pussy': 0.12115,\n",
      " 'queen': 0.02796,\n",
      " 'queer': 0.00199,\n",
      " 'redneck': 0.00155,\n",
      " 'redskin': 9e-05,\n",
      " 'retard': 0.00221,\n",
      " 'retarded': 0.00415,\n",
      " 'rube': 0.0001,\n",
      " 'sambo': 0.0001,\n",
      " 'scally': 3e-05,\n",
      " 'septic': 0.00022,\n",
      " 'shade': 0.00564,\n",
      " 'shant': 2e-05,\n",
      " 'shine': 0.00828,\n",
      " 'shiner': 0.0001,\n",
      " 'shyster': 3e-05,\n",
      " 'skinny': 0.01063,\n",
      " 'slag': 0.00043,\n",
      " 'slant': 0.00029,\n",
      " 'slit': 0.00087,\n",
      " 'slope': 0.00059,\n",
      " 'snout': 0.00011,\n",
      " 'snowflake': 0.0023,\n",
      " 'sole': 0.00179,\n",
      " 'sooty': 3e-05,\n",
      " 'spade': 0.00099,\n",
      " 'sperg': 2e-05,\n",
      " 'spic': 0.0001,\n",
      " 'spick': 3e-05,\n",
      " 'spike': 0.0022,\n",
      " 'spook': 0.00023,\n",
      " 'squaw': 6e-05,\n",
      " 'squinty': 4e-05,\n",
      " 'suntan': 5e-05,\n",
      " 'tan': 0.00632,\n",
      " 'teapot': 0.00035,\n",
      " 'tiger': 0.00441,\n",
      " 'tinker': 0.00049,\n",
      " 'tranny': 0.00305,\n",
      " 'trash': 0.0235,\n",
      " 'twat': 0.00274,\n",
      " 'uncivilised': 3e-05,\n",
      " 'uncivilized': 0.0001,\n",
      " 'wetback': 8e-05,\n",
      " 'whitey': 0.00037,\n",
      " 'wigger': 2e-05,\n",
      " 'wink': 0.00152,\n",
      " 'wog': 5e-05,\n",
      " 'wop': 0.00034,\n",
      " 'yardie': 2e-05,\n",
      " 'yellow': 0.01352,\n",
      " 'yid': 4e-05,\n",
      " 'yob': 3e-05,\n",
      " 'zebra': 0.00087,\n",
      " 'zip': 0.00336}\n"
     ]
    }
   ],
   "source": [
    "result = elasticsearch_base.aggregate(_es, \"core_tweets\", \"tokens.keyword\", False, size=20000, min_doc_count=5)\n",
    "print(\"core_tweets tweet count: {0}\".format(result[1]))\n",
    "core_tweets_hs, core_tweets_vocab = model_helpers.get_els_word_probabilities(result[0], result[1])\n",
    "pprint(core_tweets_hs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cosine_similarities = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get_word_count(hs_candidates_exp6_model, \"fuck\")\n",
    "# hs_candidates_exp6_model_vocab = li`st(hs_candidates_exp6_model.vocab.keys())\n",
    "# print(hs_candidates_exp6_model_vocab)\n",
    "# hs_candidates_exp6_model.similar_by_word(\"savages\", topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Main Twitter set\n",
      "[('blazer', 0.9450125694274902),\n",
      " ('windbreaker', 0.937454879283905),\n",
      " ('linen', 0.930109977722168),\n",
      " ('#shirt', 0.9292298555374146),\n",
      " ('hoody', 0.9283322095870972),\n",
      " ('zipper', 0.9258227348327637),\n",
      " ('trench', 0.9247759580612183),\n",
      " ('zip-up', 0.9242134094238281),\n",
      " ('shearling', 0.9210963249206543),\n",
      " ('vest', 0.9190042018890381)]\n",
      "\n",
      "Daily Stormer\n",
      "[('monkeys', 0.9646297693252563),\n",
      " ('monsters', 0.9601025581359863),\n",
      " ('thugs', 0.9567341208457947),\n",
      " ('parasites', 0.9543370604515076),\n",
      " ('illegals', 0.9494255185127258),\n",
      " ('bastards', 0.9487513303756714),\n",
      " ('barbarians', 0.947960615158081),\n",
      " ('apes', 0.9478895664215088),\n",
      " ('actors', 0.9475318193435669),\n",
      " ('gentiles', 0.9470034241676331)]\n",
      "\n",
      "Melvyn HS users\n",
      "[('degenerates', 0.8997732400894165),\n",
      " ('rings', 0.8950327634811401),\n",
      " ('assholes', 0.8936536908149719),\n",
      " ('invaders', 0.8933420181274414),\n",
      " ('barbarians', 0.8886228203773499),\n",
      " ('brands', 0.8879308700561523),\n",
      " ('cunts', 0.8854016661643982),\n",
      " ('animals', 0.8852415084838867),\n",
      " ('freaks', 0.8848967552185059),\n",
      " ('lunatics', 0.884538471698761)]\n",
      "\n",
      "Unfiltered stream\n",
      "[('morons', 0.8233602643013),\n",
      " ('motherfuckers', 0.8196897506713867),\n",
      " ('cowards', 0.8059471249580383),\n",
      " ('cunts', 0.7999811768531799),\n",
      " ('retards', 0.7997869253158569),\n",
      " ('puppets', 0.7990628480911255),\n",
      " ('scumbags', 0.7987814545631409),\n",
      " ('bullies', 0.792534589767456),\n",
      " ('bastards', 0.7921949625015259),\n",
      " ('losers', 0.789635419845581)]\n",
      "\n",
      "Manchester\n",
      "[('#washington', 0.7842807769775391),\n",
      " ('#bomber', 0.747549831867218),\n",
      " ('#political', 0.7453497648239136),\n",
      " ('#mexico', 0.7434844970703125),\n",
      " ('#helsinki', 0.7394694685935974),\n",
      " ('butcher', 0.7332726120948792),\n",
      " ('#copenhagen', 0.7295174598693848),\n",
      " ('#spain', 0.7228779792785645),\n",
      " ('hashem', 0.702467679977417),\n",
      " ('suicide-bomber', 0.6950376033782959)]\n"
     ]
    }
   ],
   "source": [
    "if embeddings:\n",
    "    print(\"\\nMain Twitter set\")\n",
    "    pprint(dep2vec_twitter.similar_by_word(\"bomber\", topn=10, restrict_vocab=None))\n",
    "    print(\"\\nDaily Stormer\")\n",
    "    pprint(dep2vec_dstormer.similar_by_word(\"savages\", topn=10, restrict_vocab=None))\n",
    "    print(\"\\nMelvyn HS users\")\n",
    "    pprint(dep2vec_melvyn_hs.similar_by_word(\"savages\", topn=10, restrict_vocab=None))\n",
    "    print(\"\\nUnfiltered stream\")\n",
    "    pprint(dep2vec_ustream.similar_by_word(\"savages\", topn=10, restrict_vocab=None))\n",
    "    print(\"\\nManchester\")\n",
    "    pprint(dep2vec_manchester.similar_by_word(\"bomber\", topn=10, restrict_vocab=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = dep2vec_twitter.similar_by_word(\"nigger\", topn=5, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp2 = [a for a in temp if a[0] in hs_keywords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spic', 0.7711798548698425),\n",
       " ('faggot', 0.7599295377731323),\n",
       " ('wetback', 0.7536832690238953),\n",
       " ('beaner', 0.747124433517456),\n",
       " ('kike', 0.7392979860305786)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754243016242981\n",
      "[('spic', 0.7711798548698425),\n",
      " ('faggot', 0.7599295377731323),\n",
      " ('wetback', 0.7536832690238953),\n",
      " ('beaner', 0.747124433517456),\n",
      " ('kike', 0.7392979860305786)]\n"
     ]
    }
   ],
   "source": [
    "def compute_avg_cosine(similarity_result):\n",
    "    cosine_vals = [cos[1] for cos in similarity_result]\n",
    "    avg_cosine = sum(cosine_vals) / len(cosine_vals)\n",
    "    return avg_cosine"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
